{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(42) \n",
    "from alive_progress import alive_bar\n",
    "import time\n",
    "from keras import backend as K\n",
    "import pickle as pkl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "scaler = MinMaxScaler()\n",
    "categorical_cross_entropy = tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Attacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker_dataset= pd.read_csv('./dataset/Bot_IoT/attacker_dataset.csv')\n",
    "attacker_dataset=attacker_dataset.drop(columns = ['attack'])\n",
    "X_train_attacker, X_test_attacker, y_train_attacker, y_test_attacker = train_test_split(attacker_dataset.drop(columns = [\"category\"]), attacker_dataset.category, stratify=attacker_dataset.category, shuffle=True, test_size=0.25,random_state=42)\n",
    "test_substitute = pd.concat([X_test_attacker, y_test_attacker], axis=1)\n",
    "\n",
    "# Model attacker Loading\n",
    "attacker_model = tf.keras.models.load_model('./models_attacker/dnnattacker', custom_objects={'categorical_cross_entropy': categorical_cross_entropy})\n",
    "#attacker_model = pkl.load(open( './models_attacker/rfattacker.pkl', 'rb'))\n",
    "\n",
    "# Model defender Loading\n",
    "defender_model= tf.keras.models.load_model('./models_defender/dnndefender', custom_objects={'categorical_cross_entropy': categorical_cross_entropy})\n",
    "#defender_model= pkl.load(open('./models_defender/rfdefender.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of adversarial attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_input = test_substitute # From the attacker\n",
    "model_input = attacker_model\n",
    "# The mask combinaisons that can be adapted in function of the studied domain. Depends of the manipulable factors\n",
    "combinaisons = [ # Don't take [000] because not relevant, so 7 combinaisons. [001] = duration, [010] = totpkt et [100] sbytes \n",
    "    [0,0,1],\n",
    "    [0,1,0],\n",
    "    [1,0,0],\n",
    "    [0,1,1],\n",
    "    [1,0,1],\n",
    "    [1,1,0],\n",
    "    [1,1,1]\n",
    "]\n",
    "\n",
    "# Define max value of each modified feature in the general dataset to project too big values on these max\n",
    "# It's the max value of the attacker or defender dataset, specified in parameter\n",
    "max_dur = dataset_input['dur'].max()\n",
    "max_pkts = dataset_input['spkts'].max()\n",
    "max_bytes = dataset_input['sbytes'].max()\n",
    "\n",
    "# Used to generate Adv Ex. Don't take the label to generate adv ex\n",
    "ben_dataset = dataset_input.loc[dataset_input['category'] == 0]\n",
    "mal_dataset = dataset_input.loc[dataset_input['category'] == 1] # 1,2, ......\n",
    "\n",
    "# Mean determination to determine during peturbation generation the direction of the perturbation (negative or positive)\n",
    "ben_mean_dur = ben_dataset['dur'].mean()\n",
    "ben_mean_Spkts = ben_dataset['spkts'].mean()\n",
    "ben_mean_Sbytes = ben_dataset['sbytes'].mean()\n",
    "\n",
    "# Reduce the dataset for the tests to speed up the generation. Just take 1000 instances here\n",
    "#mal_dataset_reduced, not_used = train_test_split(mal_dataset, shuffle=True, train_size=(1000/mal_dataset.shape[0])) # , random_state=42\n",
    "mal_dataset_reduced=mal_dataset\n",
    "mal_dataset_reduced=mal_dataset_reduced.drop(columns = ['category'])\n",
    "scaler.fit(mal_dataset_reduced.to_numpy()) # to numpy to avoid the warning later when we predict with a numpy instead of dataframe\n",
    "\n",
    "adv_ex = []\n",
    "total_ex = []\n",
    "nb_of_needed_step = 0\n",
    "\n",
    "tot_masks = []# Used to know what the most used mask to create an adversarial example\n",
    "index_of_mask = 0\n",
    "\n",
    "#max_ratio = dataset_input['RatioOutIn'].max() # Max value in RatioOutIn for the semantic constraints\n",
    "start = time.process_time()\n",
    "with alive_bar(len(mal_dataset_reduced)) as bar:\n",
    "    # For each malicious instance\n",
    "    for index, row in mal_dataset_reduced.iterrows():\n",
    "        breaked = False\n",
    "        perturb_direction = []\n",
    "        # Check the direction of perturbation for the 4 instance features\n",
    "        if(row[19] <= ben_mean_Sbytes): # Out\n",
    "            perturb_direction.append(1)\n",
    "        else:\n",
    "            perturb_direction.append(-1)          \n",
    "        if(row[17] <= ben_mean_Spkts): # spkts\n",
    "            perturb_direction.append(1)\n",
    "        else:\n",
    "            perturb_direction.append(-1)              \n",
    "        if(row[14] <= ben_mean_dur): # dur\n",
    "            perturb_direction.append(1)\n",
    "        else:\n",
    "            perturb_direction.append(-1)\n",
    "        dif_mean_dur = ben_dataset[['dur']].mean() - row[14]\n",
    "        dif_mean_dur = abs(dif_mean_dur[0])\n",
    "        dif_mean_pkts = ben_dataset[['spkts']].mean() -row[17]\n",
    "        dif_mean_pkts = abs(dif_mean_pkts[0])\n",
    "        dif_mean_bytes = ben_dataset[['sbytes']].mean() - row[19]\n",
    "        dif_mean_bytes = abs(dif_mean_bytes[0])\n",
    "        \n",
    "\n",
    "        # Max 10 iterations of iterative perturbation to try to get benign instance\n",
    "        for i in range(1, 10):\n",
    "            nb_of_needed_step += 1 # start directly at the round 1\n",
    "            # Iterate while not benign \n",
    "            if(breaked==False):\n",
    "                # For each 7 combinations of perturbations\n",
    "                for combi in combinaisons:\n",
    "                    index_of_mask += 1 # check which mask is used\n",
    "                    # add perturbation to the autorized features                    \n",
    "                    adv = np.array(row)\n",
    "\n",
    "                    perturb1 = np.array(combi[0]) * ( dif_mean_bytes * (i*0.01) * perturb_direction[0])\n",
    "                    perturb2 = np.array(combi[1]) * (dif_mean_pkts * (i*0.01) * perturb_direction[1])\n",
    "                    perturb3 = np.array(combi[2]) * (dif_mean_dur * (i*0.01) * perturb_direction[2])\n",
    "\n",
    "                    # Addition of crafted perturbation\n",
    "                    adv[19] = adv[19] + perturb1 # sBytes\n",
    "                    adv[17] = adv[17] + perturb2 # sPackets\n",
    "                    adv[17] = int(adv[17] ) \n",
    "                    adv[14] = adv[14] + perturb3 # duration  # cast in INT to keep only the integer value\n",
    "\n",
    "                    # Syntactic Constraints\n",
    "                    # Add projection on the max value present in the dataset to keep the physical limitation\n",
    "                    if(adv[14] > max_dur):\n",
    "                        adv[14] = max_dur\n",
    "                    if(adv[19] > max_bytes):\n",
    "                        adv[19] = max_bytes\n",
    "                    if(adv[17] > max_pkts):\n",
    "                        adv[17] = max_pkts\n",
    "\n",
    "                    # if there is new bytes, normaly there is also at least 1 packet\n",
    "                    if(adv[17] == 0 and adv[19] > 0):\n",
    "                        adv[17] = 1 # Maybe change this part\n",
    "\n",
    "                    if(adv[19]/adv[17]>1500):\n",
    "                        n=int((adv[19]-row[19])/1500)\n",
    "                        adv[17]=adv[17]+n+1          \n",
    "                    # Add the Semantic Contraints\n",
    "                    # Total number of Bytes in the communication. Sum of sbytes and InBytes feature values.\n",
    "                    adv[16] = adv[19]+adv[20] # TotBytes\n",
    "                    adv[15] = adv[17]+adv[18] # Totpakts\n",
    "\n",
    "                    # Average number of bytes exchanged per packet. Ratio between TotBytes and spkts.\n",
    "                    adv[21] = adv[15]/adv[14] # raet\n",
    "                    # Average number of bytes exchanged per second. Ratio between TotBytes and duration.\n",
    "                    adv[22] = adv[17]/adv[14] # Sraet\n",
    "                    # Average number of packets exchanged per second. Ratio between spkts and duration.\n",
    "                    adv[23] = adv[18]/adv[14] # Draet\n",
    "\n",
    "                    adv2 = [] # used to fit with the input of the model because normaly take a matrix, so need the matrix notation, even for a vector\n",
    "                    adv2.append(adv)\n",
    "                    adv2_scaled = scaler.transform(adv2) # For DNN\n",
    "                    test = model_input.predict(adv2_scaled)\n",
    "                    test = np.argmax(test,1) # For DNN\n",
    "                    #test = model_input.predict(adv2) # For other model than DNN\n",
    "                    if (test == 0): # benign break\n",
    "                        adv_ex.append(adv) # adv_ex contains all adversarial examples that fool the classifier\n",
    "                        breaked = True\n",
    "                        break    \n",
    "            index_of_mask = 0\n",
    "        nb_of_needed_step = 0  \n",
    "        total_ex.append(adv) # Total adversarial examples. append the final created adv ex that fool or not \n",
    "        bar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
